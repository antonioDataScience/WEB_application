{% extends 'layout.html' %}
{% block body %}
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Hints</title>
    </head>
<html>
    <body>
        <h2 style="text-align: center;">Short explanation</h2>
        <legend>Hints</legend>

        <h1>Introduction</h1>
        <p>
            This is a web application related to given tasks. The application requires more time in a sense of
            precision, design and "hacks".
            When I say "hacks" it means for example instead of passing whole row to a function I pass row[1] and row[2],
            manually picked important attributes.
            Whole calculation is based on "tpep_pickup_datetime". I didn't want to complicate more with those details.
            The application has a logic implemented
            for precise date picking. The potential problem in downloading time. CSV-s files have lots of date, so that
            could be a problem regarding to time. For example January
            in year 2018 has over 230 000 rows with same date (01.01.2018.).
        </p>
        <hr>
        <h1>Mean</h1>
        <p>
            Simply chose two dates. An algorithm will calculate the mean by each day. After that the Algorithm will
            calculate the mean of calculated means by each day.
            An implemented logic will handle wrong dates and especially wrong dates regarding to picked column. Remark,
            dates SHOULD be between "01.01.2009. and 31.12.2018.". Afterwords,
            those are given dates by https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page.
        </p>
        <hr>
        <h1>Rolling Mean</h1>
        <p>
            You have to pick two dates and window. An implemented logic will handle wrong dates and especially wrong
            dates regarding to picked column and it will slide over the dates by given
            window. Similar problems like above.
        </p>
        <hr>
        <h1>Kafka - Spark</h1>
        <p>
            This part is pure and simple simulation because CSVs data is static without complicating to much, never the
            less the implementation is here. The plan was to simulate incoming data by downloading
            data as a stream and pretend that we have real time of incoming data. The first part is handled by API -
            downloading the data and be a producer, so that API as a producer
            send data to KAFKA and SPARK as a consumer takes the data, do the mean calculation by each day on arrival. The
            next thing which spark does is sending back calculated data to KAFKA now as a producer.
            Kafka consumer takes calculated data, and a logic do the rest such as "primitive" live data streaming. This
            part can be corrected regarding to design, but this is not important right now.
            Again, this is just an example, an it can be improved :). Kafka and Spark are separated from a web
            application and they demand their own configuration not that complicated but also not not that trivial.
        </p>
         <hr>
        <p>
            antonio@antonio-VirtualBox:~/Desktop/kafka/kafka_2.12-2.2.1$ sudo bin/zookeeper-server-start.sh config/zookeeper.properties
        </p>
        <p>
            antonio@antonio-VirtualBox:~/Desktop/kafka/kafka_2.12-2.2.1$ sudo bin/kafka-server-start.sh config/server.properties
        </p>
        <hr>
        <p>
            The web application can calculate Mean and Rolling Mean without starting KAFKA and SPARK.
        </p>

    </body>
</html>
{% endblock %}